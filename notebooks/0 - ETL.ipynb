{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5437028-772d-4de9-ba3e-9c8cf526da5a",
   "metadata": {},
   "source": [
    "# ETL of the CIC IoT 2023 Dataset for Cybersecurity Research\n",
    "\n",
    "[University of New Brunswick - Canadian Institute for Cybersecurity](https://www.unb.ca/cic/datasets/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bc8124-156a-451d-adbf-d7fc419818f0",
   "metadata": {},
   "source": [
    "This notebook consolidates all the code needed to download, extract, transform and load the dataset from CIC IoT 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73252740-a25d-47bb-abc4-11b8e8ea0a0a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b62cafe-bb7c-4a8f-bae3-b8811da5f6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5d0f28-fb12-4305-b4a9-26c948b743d8",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbb661d8-10e1-4a09-81d4-a7c25310f7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_constants\n",
    "\n",
    "constants = get_constants()\n",
    "\n",
    "features = constants['features']\n",
    "path = constants['path']\n",
    "csv_path = constants['csv_path']\n",
    "parquet_path = constants['parquet_path']\n",
    "attack_category_map = constants['attack_category_map']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65d39b2-7229-4371-97cb-1cef243acfd6",
   "metadata": {},
   "source": [
    "# Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d35fe5-b486-412a-b5d0-1a8a9dfed711",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1fac092-9fab-42af-a08a-cc1a65f698c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,7G\t/var/fasttmp/dsn/CICIoT2023.zip\n"
     ]
    }
   ],
   "source": [
    "# !wget -P {path} http://205.174.165.80/IOTDataset/CIC_IOT_Dataset2023/Dataset/CSV/CICIoT2023.zip\n",
    "!du -sh {path + 'CICIoT2023.zip'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13dd47e1-8ad8-49ba-899b-ddfb2a202ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13G\t/var/fasttmp/dsn/unb_cic_csv\n",
      "CSV files: 169\n"
     ]
    }
   ],
   "source": [
    "# !unzip {constants['path'] + 'CICIoT2023.zip'} -d {constants['csv_path']}\n",
    "!du -sh {csv_path}\n",
    "!echo \"CSV files: $(ls -1q {csv_path} | wc -l)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae30a2de-2167-424c-9b66-955e6d33ffbf",
   "metadata": {},
   "source": [
    "The dataset comes as a zip of 169 CSV files. The zipped file is 2.7GB in size, and the extracted CSVs add to 13GB in disk, as we can see above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8c1c86-70da-4581-856e-3a8d6e50f9b1",
   "metadata": {},
   "source": [
    "## Load and Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0872766a-451f-42d4-b425-2d0a8be820c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_dtype = {\n",
    "    'category': [\n",
    "        'label'\n",
    "    ],\n",
    "    'bool': [\n",
    "        *features['protocol'],\n",
    "        *features['tcp_flag']\n",
    "    ],\n",
    "    'float32': [\n",
    "        *features['tcp_flag_counts'],\n",
    "        *features['flow'],\n",
    "        *features['packet'],\n",
    "    ],\n",
    "}\n",
    "\n",
    "column_dtype_map = {\n",
    "    col: dtype\n",
    "    for dtype, column_list in columns_dtype.items()\n",
    "    for col in column_list\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3d6b70-e1c4-499b-9006-910307a90cf7",
   "metadata": {},
   "source": [
    "Since most of the floating point features are related to a simple average of the pre-defined windows inside a flow, there isn't much to gain having a double precision here, so we're going to work with `float32` for all floating point values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "149d3182-d16e-4b70-b211-bd9ee339a759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 46686579 entries, 0 to 234744\n",
      "Data columns (total 48 columns):\n",
      " #   Column           Dtype   \n",
      "---  ------           -----   \n",
      " 0   flow_duration    float32 \n",
      " 1   Header_Length    float32 \n",
      " 2   Protocol Type    float32 \n",
      " 3   Duration         float32 \n",
      " 4   Rate             float32 \n",
      " 5   Srate            float32 \n",
      " 6   Drate            float32 \n",
      " 7   fin_flag_number  bool    \n",
      " 8   syn_flag_number  bool    \n",
      " 9   rst_flag_number  bool    \n",
      " 10  psh_flag_number  bool    \n",
      " 11  ack_flag_number  bool    \n",
      " 12  ece_flag_number  bool    \n",
      " 13  cwr_flag_number  bool    \n",
      " 14  ack_count        float32 \n",
      " 15  syn_count        float32 \n",
      " 16  fin_count        float32 \n",
      " 17  urg_count        float32 \n",
      " 18  rst_count        float32 \n",
      " 19  HTTP             bool    \n",
      " 20  HTTPS            bool    \n",
      " 21  DNS              bool    \n",
      " 22  Telnet           bool    \n",
      " 23  SMTP             bool    \n",
      " 24  SSH              bool    \n",
      " 25  IRC              bool    \n",
      " 26  TCP              bool    \n",
      " 27  UDP              bool    \n",
      " 28  DHCP             bool    \n",
      " 29  ARP              bool    \n",
      " 30  ICMP             bool    \n",
      " 31  IPv              bool    \n",
      " 32  LLC              bool    \n",
      " 33  Tot sum          float32 \n",
      " 34  Min              float32 \n",
      " 35  Max              float32 \n",
      " 36  AVG              float32 \n",
      " 37  Std              float32 \n",
      " 38  Tot size         float32 \n",
      " 39  IAT              float32 \n",
      " 40  Number           float32 \n",
      " 41  Magnitue         float32 \n",
      " 42  Radius           float32 \n",
      " 43  Covariance       float32 \n",
      " 44  Variance         float32 \n",
      " 45  Weight           float32 \n",
      " 46  label            category\n",
      " 47  general_label    category\n",
      "dtypes: bool(21), category(2), float32(25)\n",
      "memory usage: 5.7 GB\n",
      "CPU times: user 8min 3s, sys: 27.8 s, total: 8min 31s\n",
      "Wall time: 8min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "csv_files = (\n",
    "    filename\n",
    "    for filename in sorted(os.listdir(csv_path))\n",
    "    if filename.endswith('.csv')\n",
    ")\n",
    "\n",
    "df = pd.concat(\n",
    "    pd.read_csv(os.path.join(csv_path, csv), index_col=None, header=0, dtype=column_dtype_map)\n",
    "    for csv in csv_files\n",
    ")\n",
    "\n",
    "df['general_label'] = df['label'].map(attack_category_map).astype('category')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec92838-eb02-4ea1-9689-22c3e89f4009",
   "metadata": {},
   "source": [
    "We can see that some features names follow different patterns, but thinking about the consistency with the original dataset, we chose to keep the original names for this work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f772fb60-723d-4ac9-b615-b4690b8220bb",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21d20d5b-d017-428a-afed-f78e916ea02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960M\t/var/fasttmp/dsn/unb_cic_ds.parquet\n",
      "CPU times: user 1min 53s, sys: 5.07 s, total: 1min 59s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sort_columns = ['general_label', 'label', 'Protocol Type', 'Tot size', 'Header_Length']\n",
    "\n",
    "df.sort_values(sort_columns).to_parquet(parquet_path, index=False)\n",
    "\n",
    "!du -sh {parquet_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd4a561-ff1c-44f7-a95a-4bf6509de971",
   "metadata": {},
   "source": [
    "Here we're converting the CSVs to a parquet to make it easier to work with the data.\n",
    "\n",
    "We already define the schema and save the dataset with the values sorted to take advantage of some optimizations related to disk space usage, resulting in a dataset with less than 1GB in disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3d8f275-bfe8-4227-8376-dc21223a376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45e04211-1b88-496b-ba01-5de764f5b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -r {csv_path}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
